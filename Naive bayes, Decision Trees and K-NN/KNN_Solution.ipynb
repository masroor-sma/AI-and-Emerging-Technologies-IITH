{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"doCf_4w_ZGM5"},"source":["### K-Nearest Neighbor implementation on IRIS dataset\n","\n","This tutorial is largely based on CS231n Blog post on [KNN](https://cs231n.github.io/classification/). We encourage the students to try and implement the function below before looking it up in the above mentioned resource"]},{"cell_type":"code","metadata":{"id":"yLYCIaEhXKcd","executionInfo":{"status":"ok","timestamp":1662899883210,"user_tz":-330,"elapsed":665,"user":{"displayName":"Rahul Vigneswaran K IITH","userId":"04489749951280849829"}}},"source":["import sklearn.datasets as datasets"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"O-iGyY3hXw0S","executionInfo":{"status":"ok","timestamp":1662899888052,"user_tz":-330,"elapsed":24,"user":{"displayName":"Rahul Vigneswaran K IITH","userId":"04489749951280849829"}}},"source":["iris = datasets.load_iris()\n","# Please fill in the below function which can be used to split the data in 80:20 ratio and return 4 numpy arrays- train_x, train_y, test_x, test_y\n","# shapes- train_x: (0.8*len(iris.data),4), train_y : (0.8*len(iris.data),),test_x:(0.2*len(iris.data),4) , test_y:(0.2*len(iris.data),) \n","def dataset_splitter(iris):\n","  \n","  # space for code\n","  samples_0=[]\n","  samples_1=[]\n","  samples_2=[]\n","  for i,row in enumerate(iris.data):\n","    if iris.target[i]==0:    \n","      samples_0.append(list(row))\n","    elif iris.target[i]==1:\n","      samples_1.append(list(row))\n","    elif iris.target[i]==2:\n","      samples_2.append(list(row))\n","    \n","  train_x=(np.array(samples_0[:40]+samples_1[:40]+samples_2[:40]))\n","  train_y=np.array([0]*40+[1]*40+[2]*40)\n","  test_x=np.array(samples_0[40:]+samples_1[40:]+samples_2[40:])\n","  test_y=np.array([0]*10+[1]*10+[2]*10)\n","  \n","  return (train_x,train_y,test_x,test_y)"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"YRF-g-gDX9Bu"},"source":["import numpy as np\n","\n","# This function is taken from CS231n tutorial. Source: https://cs231n.github.io/classification/\n","class NearestNeighbor(object):\n","  def __init__(self):\n","    pass\n","\n","  def train(self, X, y):\n","    \"\"\" X is N x D where each row is an example. Y is 1-dimension of size N \"\"\"\n","    # the nearest neighbor classifier simply remembers all the training data\n","    self.Xtr = X\n","    self.ytr = y\n","\n","  def predict(self, X):\n","    \"\"\" X is N x D where each row is an example we wish to predict label for \"\"\"\n","    num_test = X.shape[0]\n","    # lets make sure that the output type matches the input type\n","    Ypred = np.zeros(num_test, dtype = self.ytr.dtype)\n","\n","    # loop over all train rows\n","    for i in range(num_test):\n","      # find the nearest training image to the i'th test image\n","      # using the L1 distance (sum of absolute value differences)\n","      distances = np.sum(np.abs(self.Xtr - X[i,:]), axis = 1)\n","      min_index = np.argmin(distances) # get the index with smallest distance\n","      Ypred[i] = self.ytr[min_index] # predict the label of the nearest example\n","\n","    return Ypred"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"j8fpz6v-bBh4"},"source":["Xtr, Ytr, Xte, Yte = dataset_splitter(iris)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DvG5IctdYHjj","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"cb8f2ade-4056-4ae1-d6f6-25edb6961db8"},"source":["nn = NearestNeighbor() # create a Nearest Neighbor classifier class\n","nn.train(Xtr, Ytr) # train the classifier on the training images and labels\n","Yte_predict = nn.predict(Xte) # predict labels on the test images\n","# and now print the classification accuracy, which is the average number\n","# of examples that are correctly predicted (i.e. label matches)\n","print('Accuracy: %f' % ( np.mean(Yte_predict == Yte) ))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Accuracy: 1.000000\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"m8gsw6JVdWsP"},"source":["#### KNN using sklearn"]},{"cell_type":"code","metadata":{"id":"rfKUK_l-biQH","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"1305a240-c7aa-45dd-a467-2c3a941070ce"},"source":["from sklearn.neighbors import KNeighborsClassifier\n","knn = KNeighborsClassifier(n_neighbors=3)\n","knn.fit(Xtr, Ytr)\n","Yte_predict = knn.predict(Xte)\n","print('accuracy: %f' % ( np.mean(Yte_predict == Yte) ))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["accuracy: 1.000000\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"reS3XbmddFdE"},"source":[],"execution_count":null,"outputs":[]}]}