{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4XElc7XH_MWa"
   },
   "source": [
    "# Lab #3: Regression Using Decision Trees\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pWMzKVUNl58c"
   },
   "source": [
    "## Data Loading\n",
    "\n",
    "We are going to create a dataset on our own.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i8AnzHBFj4qa"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "rng = np.random.RandomState(111)\n",
    "X = np.sort(10 * rng.rand(150, 1), axis=0)\n",
    "y = np.cos(X).ravel()\n",
    "y[::5] += 2 * (0.5 - rng.rand(30))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qc2olBEi_MWj"
   },
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GmRIz0Lo_MW7"
   },
   "source": [
    "#### Visualizing The Relation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mr6cEwwtlHP9"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(X, y, s=20, edgecolor=\"black\",\n",
    "            c=\"darkorange\", label=\"data\")\n",
    "plt.xlabel(\"data\")\n",
    "plt.ylabel(\"target\")\n",
    "plt.title(\"Visualizing Data\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Kuqt1xuh_MXB"
   },
   "source": [
    "## Modeling A Regressor\n",
    "\n",
    "### See [sklearn.tree.DecisionTreeRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html) docs for parameter list, attributes etc. \n",
    "\n",
    "\n",
    "The most \"relevant\" parameters:\n",
    "* **criterion** : _The function to measure the quality of a split. Supported criteria are “mse” for the mean squared error, which is equal to variance reduction as feature selection criterion and minimizes the L2 loss using the mean of each terminal node, “friedman_mse”, which uses mean squared error with Friedman’s improvement score for potential splits, and “mae” for the mean absolute error, which minimizes the L1 loss using the median of each terminal node. Default is \"mse\"._\n",
    "\n",
    "* **splitter** : _The strategy used to choose the split at each node. Supported strategies are “best” to choose the best split and “random” to choose the best random split. Default is \"best\"._\n",
    "\n",
    "* **max_depth** : _The maximum depth of the tree. If None, then nodes are expanded until all leaves are pure or until all leaves contain less than min_samples_split samples. Default is `None`._\n",
    "\n",
    "* **min_samples_split** : _The minimum number of samples required to split an internal node. Default = `2`._\n",
    "\n",
    "* **min_samples_leaf** : _The minimum number of samples required to be at a leaf node. A split point at any depth will only be considered if it leaves at least `min_samples_leaf` training samples in each of the left and right branches. This may have the effect of smoothing the model, especially in regression. Default is `1`_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wlrHPGAJ4q1d"
   },
   "source": [
    "## TO DO: Train/Test The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TlrZ9RWL4rAd"
   },
   "outputs": [],
   "source": [
    "# TO DO: Split the data into test (20%) and train sets.\n",
    "############ Your code goes here ############\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WmyfmYl-4rVM"
   },
   "source": [
    "## TO DO: Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WG9m99Vw7WzZ"
   },
   "outputs": [],
   "source": [
    "# TO DO: Train a DecisionTreeRegressor model on train set.\n",
    "\n",
    "# Parameters\n",
    "criterion = 'gini'\n",
    "splitter = 'best'\n",
    "max_depth = None\n",
    "min_samples_split = 2\n",
    "min_samples_leaf = 1\n",
    "\n",
    "############ Your code goes here ############\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MiO0MuUy40Tn"
   },
   "source": [
    "## TO DO: Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cTCETMR_4zji"
   },
   "outputs": [],
   "source": [
    "# TO DO: Test the performance of the model trained on the test set - both accuracy score and classification report should be printed.\n",
    "############ Your code goes here ############"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9A2v0TksDMlJ"
   },
   "source": [
    "## Visualizing The Decision Tree Learnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "13VIByO3_MXY"
   },
   "outputs": [],
   "source": [
    "import graphviz\n",
    "\n",
    "model = # Your model variable\n",
    "dot_data = tree.export_graphviz(model, out_file=None, \n",
    "                      feature_names=['data'],  \n",
    "                      class_names=['target'],  \n",
    "                      filled=True, rounded=True,  \n",
    "                      special_characters=True)  \n",
    "graph = graphviz.Source(dot_data)  \n",
    "graph "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C5xcixa8Ej3C"
   },
   "source": [
    "## TO DO: Regressor Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "famthVBJCPVV"
   },
   "outputs": [],
   "source": [
    "# Predict\n",
    "X_test = np.arange(0.0, 5.0, 0.01)[:, np.newaxis]\n",
    "############ Your code goes here ############\n",
    "y_1 = # Predict using the trained model\n",
    "\n",
    "# Plot\n",
    "plt.figure()\n",
    "plt.scatter(X, y, s=20, edgecolor=\"black\",\n",
    "            c=\"darkorange\", label=\"data\")\n",
    "plt.plot(X_test, y_1, color=\"cornflowerblue\",\n",
    "         label=\"max_depth={}\".format(max_depth), linewidth=2)\n",
    "plt.xlabel(\"data\")\n",
    "plt.ylabel(\"target\")\n",
    "plt.title(\"Decision Tree Regression\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "DecisionTrees_Regression_Exercise.ipynb",
   "provenance": [
    {
     "file_id": "1Otbqmf4vVuudt9jnJUMFRCCe9BhCAe12",
     "timestamp": 1559108548156
    }
   ],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
